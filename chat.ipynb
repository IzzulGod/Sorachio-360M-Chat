{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZQHQLgBdzHH0IPOBSkvEr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KyqVziHkB79b"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","\n","model_path = \"/content/drive/MyDrive/SorachioLM/models\"\n","\n","model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", torch_dtype=torch.float16)\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": \"Who are you? and who created you?\"}\n","]\n","\n","chat_input = tokenizer.apply_chat_template(messages, tokenize=False)\n","\n","inputs = tokenizer(chat_input, return_tensors=\"pt\").to(model.device)\n","outputs = model.generate(\n","    **inputs,\n","    max_new_tokens=128,\n","    temperature=0.2,\n","    top_p=0.9,\n","    top_k=100,\n","    do_sample=True,\n","    pad_token_id=tokenizer.eos_token_id\n",")\n","\n","decoded = tokenizer.decode(outputs[0], skip_special_tokens=False)\n","\n","start_token = \"<|im_start|>assistant\\n\"\n","end_token = \"<|im_end|>\"\n","\n","if start_token in decoded:\n","\n","    response_only = decoded.split(start_token)[-1].split(end_token)[0].strip()\n","else:\n","    response_only = decoded.strip()\n","\n","print(f\"Response:\\n{response_only}\")"],"metadata":{"id":"rnbgLbikCEGS"},"execution_count":null,"outputs":[]}]}